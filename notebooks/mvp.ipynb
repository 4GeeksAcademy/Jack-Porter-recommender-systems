{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest neighbors: Movie recommendation system\n",
    "\n",
    "## Notebooks set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "\n",
    "# Third party imports\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data loading\n",
    "### 1.1. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../data/raw/tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv('../data/raw/tmdb_5000_credits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the datasets (hint: you don't need SQL here - Pandas can do SQL-like joins directly). See documentation\n",
    "# for Pandas pd.merge(). Another hint: the 'movie_id' in the credits data and the 'id' in the movies data are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA\n",
    "\n",
    "### 2.1. Feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy to work with while encoding so that we have the original to go back to if needed\n",
    "encoded_data_df = data_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the features contain per-cell JSON formatted data. We can use our Python/Pandas chops to extract and parse any data we want into a useful format. This requires some item-by-item processing and is necessarily messy.\n",
    "\n",
    "In the two cells below, I wrote a function to extract the cast names two different ways - one with a loop and one using .apply(). The apply version is better, but harder to read. I included both to help you understand what the a.apply() method is doing. Take a look and both and try to write two additional .apply() lambda functions that extract the keywords and genres.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1. Extract cast names: loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to hold extracted values\n",
    "extracted_values = []\n",
    "\n",
    "# Loop on the elements of the cast column\n",
    "for json_string in data_df['cast']:\n",
    "\n",
    "    # Load the json string into a python dictionary\n",
    "    json_list = json.loads(json_string)\n",
    "\n",
    "    # Empty list to hold values from this element\n",
    "    values = []\n",
    "\n",
    "    # Loop on the first three elements of the json list\n",
    "    for item in json_list[:3]:\n",
    "\n",
    "        # Extract the value for the name key\n",
    "        value = item['name']\n",
    "\n",
    "        # Add it to the list\n",
    "        values.append(value)\n",
    "\n",
    "    extracted_values.append(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. Extract cast names: lambda apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_df['cast'] = data_df['cast'].apply(lambda x: [item['name'] for item in json.loads(x)][:3] if pd.notna(x) else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3. Extract other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for the 'keywords' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the 'genres' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result\n",
    "encoded_data_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Missing and/or extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you followed the example .apply() method to extract cast and genera, missing values should already\n",
    "# be handled, but not a bad idea to double check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Combine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the cats, keywords and genres features to one single string feature called 'tags'. This way, we\n",
    "# Have one string feature that contains a bunch of relevant information about the movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "source": [
    "## 3. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TFIDFVectorizer() from Scikit-learn to encode the tags feature, use the result to train\n",
    "# a Scikit-learn NearestNeighbors() model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommender function\n",
    "\n",
    "def get_movie_recommendations(movie_title):\n",
    "    '''Takes a movie title string, looks up TFIDF feature vector for that movie\n",
    "    and returns title of top 5 most similar movies.'''\n",
    "\n",
    "    # Your code here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Target' movie\n",
    "input_movie = \"How to Train Your Dragon\"\n",
    "\n",
    "# Call the recommendation function\n",
    "recommendations = get_movie_recommendations(input_movie)\n",
    "\n",
    "# Print the results\n",
    "print(\"Film recommendations '{}'\".format(input_movie))\n",
    "for movie, distance in recommendations:\n",
    "    print(\"- Film: {}\".format(movie))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save the assets\n",
    "\n",
    "Next week, we will be deploying this model as a web app, so save the assets needed for the model to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the assets\n",
    "encoded_data_df.to_parquet('../data/processed/movies.parquet')\n",
    "pickle.dump(model, open('../models/model.pkl', 'wb'))\n",
    "pickle.dump(tfidf_matrix, open('../data/processed/tfidf_matrix.pkl', 'wb'))\n",
    "pickle.dump(encoded_data_df, open('../data/processed/encoded_features_df.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
